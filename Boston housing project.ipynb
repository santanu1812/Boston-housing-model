{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed145cc-c44e-4e02-bbea-57cc6e5519f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be831d66-a095-4857-bf08-149d8c562e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"BostonHousing.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006d1e5-38ce-428a-b789-e1cf332e1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols=['crim','rm','age','dis','rad','medv']\n",
    "df_filtered= df[selected_cols]\n",
    "df_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097f2849-610e-492c-89dc-dfe32d66ac55",
   "metadata": {},
   "source": [
    "#### segregating the dataset into training and testing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a307ee-e17d-4352-8892-981be9080aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_filtered[['crim','rm','age','dis','rad']].values.tolist()\n",
    "y=df_filtered['medv'].values.tolist()\n",
    "Xy=list(zip(X,y))\n",
    "random.shuffle(Xy)\n",
    "Xy_train=[]; Xy_test=[]\n",
    "demarc_sample=np.floor(0.7*len(Xy))\n",
    "for i in range(len(Xy)):\n",
    "    if(i<demarc_sample):\n",
    "        Xy_train.append(Xy[i])\n",
    "    else:\n",
    "        Xy_test.append(Xy[i])\n",
    "X_train,y_train=map(list,zip(*Xy_train))\n",
    "X_test,y_test=map(list,zip(*Xy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b046e-8abb-460c-aa0a-7f14d0d79dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_filtered, hue='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c9786-412e-4d93-a228-822a0720084e",
   "metadata": {},
   "source": [
    "## standardizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b68ea-3855-4368-8fe1-d8a26861b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing X_train\n",
    "X_train_T=np.array(X_train).T\n",
    "X_train_std=[]\n",
    "mean_list=[]\n",
    "std_dev_list=[]\n",
    "for features in X_train_T:\n",
    "    mean=sum(features)/len(features)\n",
    "    mean_list.append(mean)\n",
    "    std_dev=(sum([(x-mean)**2 for x in features])/len(features))**0.5\n",
    "    std_dev_list.append(std_dev)\n",
    "    x_std=[(x-mean)/std_dev for  x in features]\n",
    "    X_train_std.append(x_std)\n",
    "X_train=np.array(X_train_std).T\n",
    "\n",
    "#normalizing X_test\n",
    "X_test_T=np.array(X_test).T\n",
    "X_test_std=[]\n",
    "for j,features in enumerate(X_test_T):\n",
    "    x_std=[(x-mean_list[j])/std_dev_list[j] for x in features]\n",
    "    X_test_std.append(x_std)\n",
    "X_test=np.array(X_test_std).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601591e4-f34f-4a3d-a494-b8cee8abbb60",
   "metadata": {},
   "source": [
    "## single batch gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9f99b-6dee-48fb-8a37-520a14d36dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history=[]\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self,X_train):\n",
    "        self.w=[random.uniform(-1,1) for _ in range(len(X_train[0]))]\n",
    "        self.b=random.uniform(-1,1)\n",
    "        \n",
    "    def loss_function(self,X_train,y_train):\n",
    "        SE=0\n",
    "        for i in range(len(X_train)):\n",
    "            y_pred=sum((wi*xi for wi,xi in zip(self.w,X_train[i])),self.b) \n",
    "            y_tg=y_train[i]\n",
    "            SE+=(y_pred-y_tg)**2\n",
    "        RMSE=(SE/len(X_train))**0.5\n",
    "        return RMSE\n",
    "        \n",
    "    def gradient_descent(self,X_train,y_train,alpha):\n",
    "        error=0\n",
    "        w_grad=[0 for _ in range(len(self.w))]\n",
    "        b_grad=0\n",
    "        for i in range(len(X_train)):\n",
    "            y_pred=sum((wi*xi for wi,xi in zip(self.w,X_train[i])),self.b) \n",
    "            y_tg=y_train[i]\n",
    "            error=(y_pred-y_tg)\n",
    "            for j in range(len(self.w)):\n",
    "                w_grad[j]+=error*X_train[i][j]\n",
    "            b_grad+=error\n",
    "        for k in range(len(self.w)):\n",
    "            self.w[k]+=(-2/len(X_train))*alpha*w_grad[k]\n",
    "        self.b+=(-2/len(X_train))*alpha*b_grad\n",
    "        return f' w={self.w} , b={self.b}'\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        prediction=[]\n",
    "        for i in range(len(X_test)):\n",
    "            prediction.append(sum((wi*xi for wi,xi in zip(self.w,X_test[i])),self.b))\n",
    "        return prediction\n",
    "\n",
    "    def R_squared(self,X_test,y_test):\n",
    "        y_mean=sum(y_test)/len(y_test)\n",
    "        TSS=sum([(y-y_mean)**2 for y in y_test])\n",
    "        y_pred=[]\n",
    "        for i in range(len(X_test)):\n",
    "            y_pred.append(sum((wi*xi for wi,xi in zip(self.w,X_test[i])),self.b))\n",
    "        RSS=sum([(y1-y2)**2 for y1,y2 in zip(y_pred,y_test)])\n",
    "        return 1-(RSS/TSS)\n",
    "\n",
    "epochs=1000\n",
    "\n",
    "model=LinearRegression(X_train)\n",
    "for i in range(epochs):\n",
    "    model.gradient_descent(X_train,y_train,alpha=0.01)\n",
    "    print(model.loss_function(X_train,y_train))\n",
    "    loss_history.append(model.loss_function(X_train,y_train))         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08aa9a-2f82-464f-9304-a70fdd5e0259",
   "metadata": {},
   "source": [
    " ##### the model's RMSE would not converge to zero because of the noise in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7210ec-bc6e-4061-868e-91d7086fb8a2",
   "metadata": {},
   "source": [
    "### plotting the RMSE for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeead0-2912-4b37-8cfc-9a5a9fbe56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(epochs),y=loss_history, color='red', linewidth=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e16a55-f14b-4d75-9ba7-c5269138812d",
   "metadata": {},
   "source": [
    "## testing our model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b97b77-65b2-4e8f-9b73-06fc50497776",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[float(x) for x in model.predict(X_test)]\n",
    "print(*y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e4042-a0a8-42e9-9f1a-6e0e23934f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test,y=y_pred)\n",
    "sns.lineplot(x=y_test,y=y_test, linestyle='--',color='red')\n",
    "plt.xlabel(\"actual median value\"); plt.ylabel(\"predicted median value\")\n",
    "plt.title(\"Accuracy of my model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156bf8d-f6cb-408c-b01e-5465bf74bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.R_squared(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c3ac9-2a06-43c6-99b5-3a72f73084db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ENV_1)",
   "language": "python",
   "name": "env_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
